{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avani Gupta <br>\n",
    "Roll: 2019121004 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwxWcO7fqb-L"
   },
   "source": [
    "# Excercise - Multi-class classification of MNIST using Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcygblmOmQDZ"
   },
   "source": [
    "In binary perceptron, where $\\mathbf{y} \\in \\{-1, +1\\}$, we used to update our weights only for wrongly classified examples.\n",
    "\n",
    "The multi-class perceptron is regarded as a generalization of binary perceptron. Learning through iteration is the same as the perceptron. Weighted inputs are passed through a multiclass signum activation function. If the predicted output label is the same as true label then weights are not updated. However, when predicted output label $\\neq$ true label, then the wrongly classified input example is added to the weights of the correct label and subtracted from the weights of the incorrect label. Effectively, this amounts to ’rewarding’ the correct weight vector, ’punishing’ the misleading, incorrect weight\n",
    "vector, and leaving alone an other weight vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set();\n",
    "import pandas as pd\n",
    "import math\n",
    "import gif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223975,
     "status": "ok",
     "timestamp": 1596984132348,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "gNkGLnbjTY-s"
   },
   "outputs": [],
   "source": [
    "# Setting the seed to ensure reproducibility of experiments\n",
    "np.random.seed(11)\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "def one_hot(a):\n",
    "  b = -1 * np.ones((a.size, a.max()+1))\n",
    "  b[np.arange(a.size), a] = 1\n",
    "  return b\n",
    "\n",
    "# Loading digits datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# One-hot encoding of target label, Y\n",
    "Y = digits.target\n",
    "Y = one_hot(Y)\n",
    "\n",
    "# Adding column of ones to absorb bias b of the hyperplane into X\n",
    "X = digits.data\n",
    "bias_ones = np.ones((len(X), 1))\n",
    "X = np.hstack((X, bias_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223957,
     "status": "ok",
     "timestamp": 1596984132353,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "0BPvc5P8KvrM",
    "outputId": "233f09b1-7641-4c60-c21d-74a2264f8bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:  (1257, 65)\n",
      "Validation dataset:  (180, 65)\n",
      "Test dataset:  (360, 65)\n"
     ]
    }
   ],
   "source": [
    "# Train-val-test data\n",
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, shuffle=True, test_size = 0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size = 0.12517)\n",
    "\n",
    "print(\"Training dataset: \", X_train.shape)\n",
    "print(\"Validation dataset: \", X_val.shape)\n",
    "print(\"Test dataset: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 223939,
     "status": "ok",
     "timestamp": 1596984132358,
     "user": {
      "displayName": "KARTIK RISHI BHARADWAJ 14BEE0070",
      "photoUrl": "",
      "userId": "12368401133146776355"
     },
     "user_tz": -330
    },
    "id": "QPJZdeDtUfoy",
    "outputId": "66a50417-5c21-4158-f029-20ef755e50f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAL0UlEQVR4nO3d34tc9RnH8c/HNcEfSVyIVtSIqVACInQTJFQC0iYqsUr0ohcJVIi0pBetGBoQ7U2Tf0DSiyKEqAkYIxoNFGmtAV1EaLVJXGt0YzEh4jbq+oOwiYUGzdOLOSlpuu2eXc/3zOw87xcMmdmdOc+zu/nMOWfmzHkcEQLQ3y7odgMAyiPoQAIEHUiAoAMJEHQgAYIOJNATQbe92vZ7tt+3/VDhWo/bHrd9qGSdc+pda/sV26O237H9QOF6F9l+w/ZbVb0tJetVNQdsv2n7hdK1qnrHbL9te8T2/sK1Bm3vsX24+hveXLDWkupnOnuZsL2xkYVHRFcvkgYkHZF0vaS5kt6SdEPBerdIWibpUEs/31WSllXX50v6W+Gfz5LmVdfnSHpd0vcK/4y/lPSUpBda+p0ek3R5S7V2SvppdX2upMGW6g5I+ljSdU0srxfW6MslvR8RRyPitKSnJd1dqlhEvCrpi1LLn6TeRxFxsLp+UtKopGsK1ouIOFXdnFNdih0VZXuRpDslbS9Vo1tsL1BnxfCYJEXE6Yg40VL5VZKORMQHTSysF4J+jaQPz7k9poJB6CbbiyUtVWctW7LOgO0RSeOS9kVEyXpbJT0o6UzBGucLSS/ZPmB7Q8E610v6VNIT1a7JdtuXFqx3rrWSdje1sF4Iuif5Wt8dl2t7nqTnJG2MiImStSLi64gYkrRI0nLbN5aoY/suSeMRcaDE8v+PFRGxTNIdkn5u+5ZCdS5UZzfv0YhYKulLSUVfQ5Ik23MlrZH0bFPL7IWgj0m69pzbiyQd71IvRdieo07Id0XE823VrTYzhyWtLlRihaQ1to+ps8u10vaThWr9W0Qcr/4dl7RXnd2/EsYkjZ2zRbRHneCXdoekgxHxSVML7IWg/0XSd2x/u3omWyvpd13uqTG2rc4+3mhEPNJCvStsD1bXL5Z0q6TDJWpFxMMRsSgiFqvzd3s5In5cotZZti+1Pf/sdUm3SyryDkpEfCzpQ9tLqi+tkvRuiVrnWacGN9ulzqZJV0XEV7Z/IemP6rzS+HhEvFOqnu3dkr4v6XLbY5J+HRGPlaqnzlrvXklvV/vNkvSriPh9oXpXSdppe0CdJ/JnIqKVt71acqWkvZ3nT10o6amIeLFgvfsl7apWQkcl3VewlmxfIuk2ST9rdLnVS/kA+lgvbLoDKIygAwkQdCABgg4kQNCBBHoq6IUPZ+xaLepRr9v1eiroktr8Zbb6h6Me9bpZr9eCDqCAIgfM2O7ro3AGBgam/ZgzZ87oggtm9rx69dVXT/sxp06d0rx582ZUb+HChdN+zOeffz6jx0nSyZMnp/2YiYkJLViwYEb1jhw5MqPHzRYR8V8fFOv6IbCz0fz581utt2nTplbrrV+/vtV6w8PDrda75557Wq3XC9h0BxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQQK2gtzkyCUDzpgx6dZLB36pzCtobJK2zfUPpxgA0p84avdWRSQCaVyfoaUYmAf2qzodaao1Mqj4o3/ZndgHUUCfotUYmRcQ2Sduk/v+YKjDb1Nl07+uRSUAGU67R2x6ZBKB5tU48Uc0JKzUrDEBhHBkHJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABJrXMwI4dO1qtd/fd7X4qeMuWLa3Wa3syTNv12v7/MhnW6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUigzkimx22P2z7URkMAmldnjb5D0urCfQAoaMqgR8Srkr5ooRcAhbCPDiTQ2MdUmb0G9K7Ggs7sNaB3sekOJFDn7bXdkv4kaYntMds/Kd8WgCbVGbK4ro1GAJTDpjuQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQT6Yvba4sWLW63X9iy0nTt3tlpv8+bNrdYbHBxstd7Q0FCr9XoBa3QgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kUOfkkNfafsX2qO13bD/QRmMAmlPnWPevJG2KiIO250s6YHtfRLxbuDcADakze+2jiDhYXT8paVTSNaUbA9Ccae2j214saamk10s0A6CM2h9TtT1P0nOSNkbExCTfZ/Ya0KNqBd32HHVCvisinp/sPsxeA3pXnVfdLekxSaMR8Uj5lgA0rc4++gpJ90paaXukuvywcF8AGlRn9tprktxCLwAK4cg4IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJ9MXstRMnTnS7haJ27NjR7RaK6ve/Xy9gjQ4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEE6pwF9iLbb9h+q5q9tqWNxgA0p86x7v+UtDIiTlXnd3/N9h8i4s+FewPQkDpngQ1Jp6qbc6oLAxqAWaTWPrrtAdsjksYl7YsIZq8Bs0itoEfE1xExJGmRpOW2bzz/PrY32N5ve3/TTQL4Zqb1qntEnJA0LGn1JN/bFhE3RcRNDfUGoCF1XnW/wvZgdf1iSbdKOly6MQDNqfOq+1WSdtoeUOeJ4ZmIeKFsWwCaVOdV979KWtpCLwAK4cg4IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJ9MXstaGhoW63APQ01uhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IoHbQqyEOb9rmxJDALDOdNfoDkkZLNQKgnLojmRZJulPS9rLtACih7hp9q6QHJZ0p2AuAQupMarlL0nhEHJjifsxeA3pUnTX6CklrbB+T9LSklbafPP9OzF4DeteUQY+IhyNiUUQslrRW0ssR8ePinQFoDO+jAwlM61RSETGszthkALMIa3QgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwn0xey1kZGRbrdQ1GWXXdZqvcHBwVbrtT07b/Pmza3W6wWs0YEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpBArUNgq1M9n5T0taSvOKUzMLtM51j3H0TEZ8U6AVAMm+5AAnWDHpJesn3A9oaSDQFoXt1N9xURcdz2tyTts304Il499w7VEwBPAkAPqrVGj4jj1b/jkvZKWj7JfZi9BvSoOtNUL7U9/+x1SbdLOlS6MQDNqbPpfqWkvbbP3v+piHixaFcAGjVl0CPiqKTvttALgEJ4ew1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAKOiOYXaje/0B4yPDzc7RaKOnbsWLdbKGr9+vXdbqGoiPD5X2ONDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQRqBd32oO09tg/bHrV9c+nGADSn7gCH30h6MSJ+ZHuupEsK9gSgYVMG3fYCSbdIWi9JEXFa0umybQFoUp1N9+slfSrpCdtv2t5eDXL4D7Y32N5ve3/jXQL4RuoE/UJJyyQ9GhFLJX0p6aHz78RIJqB31Qn6mKSxiHi9ur1HneADmCWmDHpEfCzpQ9tLqi+tkvRu0a4ANKruq+73S9pVveJ+VNJ95VoC0LRaQY+IEUnsewOzFEfGAQkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgNlrMzA4ONhqva1bt7Zab2hoqNV6bc9CGxkZabVe25i9BiRF0IEECDqQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJDBl0G0vsT1yzmXC9sY2mgPQjCnPGRcR70kakiTbA5L+Lmlv4b4ANGi6m+6rJB2JiA9KNAOgjOkGfa2k3SUaAVBO7aBX53RfI+nZ//F9Zq8BParuAAdJukPSwYj4ZLJvRsQ2Sduk/v+YKjDbTGfTfZ3YbAdmpVpBt32JpNskPV+2HQAl1B3J9A9JCwv3AqAQjowDEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSKDV77VNJM/nM+uWSPmu4nV6oRT3qtVXvuoi44vwvFgn6TNneHxE39Vst6lGv2/XYdAcSIOhAAr0W9G19Wot61OtqvZ7aRwdQRq+t0QEUQNCBBAg6kABBBxIg6EAC/wKMjH+/mXElygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.reset_orig();\n",
    "\n",
    "plt.gray()\n",
    "plt.matshow(digits.images[10])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2KVp57S1Zah"
   },
   "source": [
    "#### Write your code below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tut notebook functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining signum activation function\n",
    "def signum(vec_w_x):\n",
    "  \"\"\" signum activation for perceptron\n",
    "\n",
    "  Parameters\n",
    "  ------------\n",
    "  vec_w_x: ndarray\n",
    "    Weighted inputs\n",
    "  \"\"\"\n",
    "\n",
    "  vec_w_x[vec_w_x >= 0] = 1\n",
    "  vec_w_x[vec_w_x < 0] = -1\n",
    "  return vec_w_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-class signum\n",
    "def multi_class_signum(vec_w_x):\n",
    "  \"\"\" Multiclass signum activation.\n",
    "\n",
    "  Parameters\n",
    "  ------------\n",
    "  vec_w_x: ndarray\n",
    "    Weighted inputs\n",
    "  \"\"\"\n",
    "\n",
    "  flag = np.all(vec_w_x == 0)\n",
    "\n",
    "  if flag:\n",
    "    return vec_w_x\n",
    "\n",
    "  else:\n",
    "    num_examples, num_outputs = np.shape(vec_w_x)\n",
    "    range_examples = np.array(range(0, num_examples))\n",
    "\n",
    "    zero_idxs = np.argwhere(np.all(vec_w_x == 0, axis=1))\n",
    "    non_zero_examples = np.delete(range_examples, zero_idxs[:, 0])\n",
    "      \n",
    "    signum_vec_w_x = vec_w_x[non_zero_examples]\n",
    "    maxvals = np.amax(signum_vec_w_x, axis=1)\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "      idx = np.argwhere(signum_vec_w_x == maxvals[i])[0]\n",
    "      signum_vec_w_x[idx[0], idx[1]] = 1\n",
    "\n",
    "    non_maxvals_idxs = np.argwhere(signum_vec_w_x != 1)\n",
    "    signum_vec_w_x[non_maxvals_idxs[:, 0], non_maxvals_idxs[:, 1]] = -1\n",
    "    vec_w_x[non_zero_examples] = signum_vec_w_x\n",
    "\n",
    "    return vec_w_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation for train, val, and test set.\n",
    "def get_accuracy(y_predicted, Y_input_set, num_datapoints):\n",
    "  miscls_points = np.argwhere(np.any(y_predicted != Y_input_set, axis=1))\n",
    "  miscls_points = np.unique(miscls_points)\n",
    "  accuracy = (1-len(miscls_points)/num_datapoints)*100\n",
    "  return accuracy\n",
    "\n",
    "def get_prediction(X_input_set, Y_input_set, weights, get_acc=True, model_type='perceptron', predict='no'):\n",
    "\n",
    "  if len(Y_input_set) != 0:\n",
    "    num_datapoints, num_categories = np.shape(Y_input_set)\n",
    "\n",
    "  vec_w_transpose_x = np.dot(X_input_set, weights)\n",
    "\n",
    "  if num_categories > 1: # Multi-class\n",
    "    if model_type == 'perceptron':\n",
    "      y_pred_out = multi_class_signum(vec_w_transpose_x)\n",
    "    elif model_type == 'logreg':\n",
    "      y_pred_out = softmax(X_input_set, vec_w_transpose_x, predict=predict)\n",
    "\n",
    "  else: # Binary class\n",
    "    if model_type == 'perceptron' or model_type == 'LinearDA':\n",
    "      y_pred_out = signum(vec_w_transpose_x)\n",
    "    elif model_type == 'logreg':\n",
    "      y_pred_out = sigmoid(vec_w_transpose_x, predict=predict)\n",
    "\n",
    "  # Both prediction and evaluation\n",
    "  if get_acc:\n",
    "    cls_acc = get_accuracy(y_pred_out, Y_input_set, num_datapoints)\n",
    "    return cls_acc\n",
    "  \n",
    "  # Only prediction\n",
    "  return y_pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perceptron training algorithm\n",
    "def train(X_train, Y_train, weights, learning_rate=1, total_epochs=100):\n",
    "\n",
    "  \"\"\"Training method for Perceptron.\n",
    "  \n",
    "  Parameters\n",
    "  -----------\n",
    "\n",
    "  X_train: ndarray (num_examples(rows) vs num_features(columns))\n",
    "    Input dataset which perceptron will use to learn optimal weights\n",
    "  \n",
    "  Y_train: ndarray (num_examples(rows) vs class_labels(columns))\n",
    "    Class labels for input data\n",
    "\n",
    "  weights: ndarray (num_features vs n_output)\n",
    "    Weights used to train the network and predict on test set\n",
    "\n",
    "  learning_rate: int\n",
    "    Learning rate use to learn and update weights\n",
    "  \n",
    "  total_epochs: int\n",
    "    Max number of epochs to train the perceptron model\n",
    "  \"\"\"\n",
    "\n",
    "  n_samples, _ = np.shape(X_train)\n",
    "  history_weights = []\n",
    "  epoch = 1\n",
    "\n",
    "  # Number of missclassified points we would like to see in the train set.\n",
    "  # While training, its value will change every epoch. If m==0, our training \n",
    "  # error will be zero.\n",
    "  m = 1\n",
    "\n",
    "  # If the most recent weights gave 0 misclassifications, break the loop.\n",
    "  # Else continue until total_epochs is completed.\n",
    "  while m != 0 and epoch <= total_epochs:\n",
    "    m = 0\n",
    "\n",
    "    # Compute weighted inputs and predict class labels on training set.\n",
    "    weights_transpose_x = np.dot(X_train, weights)\n",
    "    weights_transpose_x = signum(weights_transpose_x)\n",
    "    y_train_out = np.multiply(Y_train, weights_transpose_x)\n",
    "    epoch += 1\n",
    "    \n",
    "    # Collecting misclassified indexes and count them\n",
    "    y_miscls_idxs = np.argwhere(y_train_out <= 0)[:, 0]\n",
    "    y_miscls_idxs = np.unique(y_miscls_idxs)\n",
    "    m = len(y_miscls_idxs)\n",
    "\n",
    "    # Calculate gradients and update weights\n",
    "    dweights = np.dot((X_train[y_miscls_idxs]).T, Y_train[y_miscls_idxs])\n",
    "    weights += (learning_rate/n_samples) * dweights\n",
    "    weights = np.round(weights, decimals=4)\n",
    "\n",
    "    # Append weights to visualize decision boundary later\n",
    "    history_weights.append(weights)\n",
    "\n",
    "  if m == 0 and epoch <= total_epochs:\n",
    "    print(\"Training has stabilized with all points classified: \", epoch)\n",
    "  else:\n",
    "    print(f'Training completed at {epoch-1} epochs. {m} misclassified points remain.')\n",
    "\n",
    "  return history_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training has stabilized with all points classified:  219\n",
      "Training completed at 10000 epochs. 17 misclassified points remain.\n",
      "Training has stabilized with all points classified:  104\n",
      "Training has stabilized with all points classified:  1360\n",
      "Training has stabilized with all points classified:  237\n",
      "Training has stabilized with all points classified:  426\n",
      "Training has stabilized with all points classified:  332\n",
      "Training has stabilized with all points classified:  309\n",
      "Training completed at 10000 epochs. 40 misclassified points remain.\n",
      "Training completed at 10000 epochs. 12 misclassified points remain.\n"
     ]
    }
   ],
   "source": [
    "weights_arr = np.zeros((X_train.shape[1], Y_train.shape[1]))\n",
    "for i in range(Y_train.shape[1]):\n",
    "    weights = np.zeros((X_train.shape[1], 1))\n",
    "    weights_arr[:, i:i+1] = train(X_train, Y_train[:, i].reshape((-1,1)), weights, 1, 10000)[-1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, W):\n",
    "    pred = X @ W\n",
    "    Class_value = np.max(pred, axis=1, keepdims=True)\n",
    "    pred = (pred == Class_value )\n",
    "    class1 = np.where(Y == 1, True, False)\n",
    "    match = pred[class1]\n",
    "    acc = np.mean(match) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  99.0453460620525\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy(X_train, Y_train, weights_arr)\n",
    "print(\"Train accuracy: \",train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  95.0\n",
      "Test accuracy:  96.66666666666667\n"
     ]
    }
   ],
   "source": [
    "val_acc = accuracy(X_val, Y_val, weights_arr)\n",
    "print(\"Validation accuracy: \", val_acc)\n",
    "test_acc = accuracy(X_test, Y_test, weights_arr)\n",
    "print(\"Test accuracy: \", test_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ZQQfFFOrqST3"
   ],
   "name": "LinearPerceptron_draft4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
